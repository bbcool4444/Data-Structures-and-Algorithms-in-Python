{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Experimental Studies\n",
    "\n",
    "#### 3.1.1 Moving Beyond Experimental Analysis\n",
    "\n",
    "Our goal is to develop an approach to analyzing the efficiency of algorithms that:\n",
    "1. Allows us to evaluate the relative efficiency of any two algorithms in a way that is independent of the hardware and software environment.\n",
    "2. Is performed by studying a high-level description of the algorithm without need for implementation.\n",
    "3. Takes into account all possible inputs.\n",
    "\n",
    "**primitive operations** such as the following:\n",
    "\n",
    "* Assigning an identifier to an object\n",
    "* Determining the object associated with an identifier\n",
    "* Performing an arithmetic operation (for example, adding two numbers)\n",
    "* Comparing two numbers\n",
    "* Accessing a single element of a Python list by index\n",
    "* Calling a function (excluding operations executed within the function)\n",
    "* Returning from a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Seven Functions Used in This Book\n",
    "\n",
    "##### 1. The Constant Function\n",
    "\n",
    "$f(n) = c$\n",
    "\n",
    "##### 2. The Logarithm Function\n",
    "\n",
    "**Proposition 3.1** *(Logarithm Rules) Given real numbers a > 0, b > 1, c > 0 and d > 1, we have:*\n",
    "\n",
    "1. $\\log_b(ac) = log_ba + log_bc$\n",
    "\n",
    "2. $\\log_b(a/c) = log_ba - log_bc$\n",
    "\n",
    "3. $\\log_b(a^c) = clog_ba$\n",
    "\n",
    "4. $\\log_ba = log_da / log_db$\n",
    "\n",
    "5. $b^{\\log_da} = a^{log_db}$\n",
    "\n",
    "##### 3. The Linear Function\n",
    "\n",
    "$f(n) = n$\n",
    "\n",
    "##### 4. The N-Log-N Function\n",
    "\n",
    "$f(n) = nlogn$\n",
    "\n",
    "##### 5. The Quadratic Function\n",
    "\n",
    "$f(n) = n^2$\n",
    "\n",
    "##### 6. The Cubic Function\n",
    "\n",
    "$f(n) = n^3$\n",
    "\n",
    "##### Polynomials\n",
    "Most of the functions we have listed so far can each be viewed as being part of a larger class of functions, the **polynomials**. A polynomial function has the form,\n",
    "\n",
    "$f(n) = a_0 +a_1n+a_2n^2 +a_3n^3 +···+a_dn^d$\n",
    "\n",
    "where $a_0$, $a_1$ , . . . , $a_d$ are constants, called the **coefficients** of the polynomial, and $a_d \\neq 0$. Integer $d$, which indicates the highest power in the polynomial, is called the **degree** of the polynomial.\n",
    "\n",
    "##### 7. The Exponential Function\n",
    "**Proposition 3.4** *(Exponent Rules): Given positive integers $a$, $b$, and $c$, we have*\n",
    "\n",
    "1. $(b^a)^c = b^{ac}$\n",
    "\n",
    "2. $b^ab^c = b^{a+c}$\n",
    "\n",
    "3. $b^a/b^c = b^{a-c}$\n",
    "\n",
    "$b^{a/c} = (b^a)^{1/c}$ extended from Exponent rule 1.\n",
    "\n",
    "$b^d = 1/b^{-d}$ extended from Exponent rule 3\n",
    "\n",
    "##### Geometric Sums\n",
    "**Proposition 3.5**: *For any integer $n ≥ 0$ and any real number $a$ such that $a > 0$ and $a \\neq 1$, consider the summation*\n",
    "\n",
    "$\\sum_{i=0}^na^i = 1 + a + a^2 + \\cdots + a^n$\n",
    "\n",
    "*(remembering that $a^0 = 1$ if $a > 0$). This summation is equal to*\n",
    "\n",
    "$\\tfrac{a^{n+1}-1}{a-1}$\n",
    "\n",
    "##### 3.2.1 Comparing Growth Rates\n",
    "\n",
    "##### floor function and ceiling function\n",
    "\n",
    "$\\lfloor x \\rfloor$ = the largest integer less than or equal to $x$.\n",
    "\n",
    "$\\lceil x \\rceil$ = the smallest integer greater than or equal to $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Asymptotic Analysis\n",
    "\n",
    "#### 3.3.1 The “Big-Oh” Notation\n",
    "\n",
    "Let $f(n)$ and $g(n)$ be functions mapping positive integers to positive real numbers. We say that $f(n)$ is $O(g(n))$ if there is a real constant $c > 0$ and an integer constant $n_0 ≥ 1$ such that\n",
    "\n",
    "$f(n) ≤ cg(n)$, for $n ≥ n_0$.\n",
    "\n",
    "This definition is often referred to as the “big-Oh” notation, for it is sometimes pronounced as “$f(n)$ is ***big-Oh*** of $g(n)$.”\n",
    "\n",
    "It is considered poor taste to say “$f(n) ≤ O(g(n))$,” since the big-Oh already denotes the “less-than-or-equal-to” concept. Likewise, although common, it is not fully correct to say “$f(n) = O(g(n))$,” with the usual understanding of the “$=$” relation, because there is no way to make sense of the symmetric statement, “$O(g(n)) = f(n)$.” It is best to say,\n",
    "\n",
    "“$f(n)$ ***is*** $O(g(n))$.”\n",
    "\n",
    "Alternatively, we can say “$f(n)$ is ***order of*** $g(n)$.”\n",
    "\n",
    "**Proposition 3.7** *The algorithm, find max, for computing the maximum element of a list of n numbers, runs in O(n) time.*\n",
    "\n",
    "The initialization before the loop begins requires only a constant number of primitive operations. Each iteration of the loop also requires only a constant number of primitive operations, and the loop execute $n$ times. Therefore, we account for the number of primitive operations being $c' + c''x$ for appropriate constants $c'$ and $c''$ that reflect, respectively, the work performed during inialization and the loop body. Because each primitive operation runs in constant time, we have that the running time of algorithm `find_max` on an input of size $n$ is at most a constant times $n$; that is, we conclude that the running time of algorithm find_max is $O(n)$.\n",
    "\n",
    "##### Some Properties of the Big-Oh Notation\n",
    "\n",
    "**Proposition 3.9**: *If $f(n)$ is a polynomial of degree $d$, that is,*\n",
    "\n",
    "$f(n) = a_0 +a_1n+···+a_dn^d$,\n",
    "\n",
    "*and $ad > 0$, then $f(n)$ is $O(nd)$.*\n",
    "\n",
    "**Justification**: Note that, for $n ≥ 1$, we have $1 ≤ n ≤ n2 ≤ ··· ≤ n^d$; hence,\n",
    "\n",
    "$a_0+a_1n+a_2n^2 +···+a_dn^d ≤ (|a0|+|a1|+|a2|+···+|ad|)n^d$\n",
    "\n",
    "We show that $f(n)$ is $O(n^d)$ by defining $c = |a_0|+|a_1|+···+|a_d|$ and $n_0 = 1$.\n",
    "\n",
    "##### Characterizing Functions in Simplest Terms\n",
    "\n",
    "##### Big-Omega\n",
    "\n",
    "$f(n) ≥ cg(n)$, for $n ≥ n_0$\n",
    "\n",
    "##### Big-Theat\n",
    "\n",
    "$c'g(n) ≤ f(n) ≤ c''g(n)$ for $n ≥ n_0$\n",
    "\n",
    "#### 3.3.3 Examples of Algorithm Analysis\n",
    "\n",
    "##### Constant-Time Operations\n",
    "\n",
    "Therefore, we say that the expression data[j] is evaluated in $O(1)$ time for a Python list.\n",
    "\n",
    "##### Prefix Averages\n",
    "\n",
    "The next problem we consider is computing what are known as ***prefix averages*** of a sequence of numbers. Namely, given a sequence `S` consisting of `n` numbers, we want to compute a sequence `A` such that $A[j]$ is the average of elements $S[0], ..., S[j]$, for $j = 0,..., n-1$, that is,\n",
    "\n",
    "$A[j] = \\tfrac{\\sum^j_{i=0}S[i]}{j+1}$\n",
    "\n",
    "##### Three-Way Set Disjointness\n",
    "\n",
    "The ***three-way set disjointness*** problem is to determine if the intersection of the three sequences is empty, namely, that there is no element x such that $x∈A, x∈B$, and $x∈C$.\n",
    "\n",
    "##### Element Uniqueness\n",
    "A problem that is closely related to the three-way set disjointness problem is the ***element uniqueness problem***. In the former, we are given three collections and we presumed that there were no duplicates within a single collection. In the element uniqueness problem, we are given a single sequence $S$ with $n$ elements and asked whether all elements of that collection are distinct from each other.\n",
    "\n",
    "##### Using Sorting as a Problem-Solving Tool\n",
    "\n",
    "The built-in function, `sorted`. It guarantees a worst-case running time of $O(nlogn)$;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Simple Justification Techniques\n",
    "\n",
    "##### 3.4.1 By Example\n",
    "***counterexample***\n",
    "\n",
    "##### 3.4.2 The \"Contra\" Attack\n",
    "\n",
    "***contrapositive***\n",
    "\n",
    "***contradiction***\n",
    "\n",
    "##### 3.4.3 Induction and Loop Invariants\n",
    "\n",
    "##### Induction\n",
    "\n",
    "**Proposition 3.20:** *Consider the Fibonacci function $F(n)$, which is defined such that $F(1) = 1$, $F(2) = 2$, and $F(n) = F(n-2) + F(n-1)$ for $n > 2$. (See Section 1.8.) We claim that $F(n) < 2n$.*\n",
    "\n",
    "**Justification:** We will show our claim is correct by induction.\n",
    "\n",
    "***Basecases:*** $(n≤2)$.$F(1)=1<2=2^1$ and$F(2)=2<4=2^2$.\n",
    "\n",
    "***Induction step:*** $(n > 2)$. Suppose our claim is true for all $n' < n$. Consider $F(n)$. Since $n > 2$, $F(n) = F(n-2) + F(n-1)$. Moreover, since both $n-2$ and $n-1$ are less than $n$, we can apply the inductive assumption (sometimes called the “inductive hypothesis”) to imply that $F(n) < 2^{n-2} + 2^{n-1}$, since\n",
    "\n",
    "$2^{n-2} + 2^{n-1} < 2^{n-1} + 2^{n-1} = 2\\cdot2^{n-1} = 2^n$\n",
    "\n",
    "##### Loop Invariants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
